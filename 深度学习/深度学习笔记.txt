机器学习是深度学习的基础
资源： github， kaggle

图像的挑战
	1.照射角度
	2.光照强度
	3.形状改变
	4.部分遮蔽
	5.背景混入
常规套路
	1.收集数据并给定标签
	2.训练一个分类器
	3.测试，评估
K-近领算法
	// 不需要训练集进行训练,训练时间浮渣度为0
	1.计算已知类别数据集中的点与当前点的距离
	2.按照距离依次排序
	3.选取与当前点距离最小的K个点
	4.确定前K个点所在类别的出现概率
	5.返回前K个点出现频率最高的类别作为当前点预测分类
anaconda 安装Python第三方库
	anaconda search -t conda tensorflow
	anaconda show jjhelmus/tensorflow	
	 conda install --channel https://conda.anaconda.org/jjhelmus tensorflow
正则惩罚项
	用于惩罚权重, 
		比如 X = 1,0,0,0; w1 = 1,0,0,0; w2=1/4, 1/4, 1/4; w1X = 1, W2X也等于1; 但是w1中只考虑到了一个特征
		

		这时w1的惩罚回避w2重
评价一个模型: 
	损失函数 + 正则惩罚项
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
			Soft分类器: 用于分类
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
Softmax的输出(归一化的分类概率)
	1.先把得分值映射到一个大的区间(e^x)
	2.归一化操作, 得到一个概率值
	3.那正确类别计算损失值: = -log(概率)
损失函数: 交叉熵损失
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
			最优化形象解读
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
梯度下降: 通过优化权重w, 来使损失函数达到最小值来求取最优解

yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
			反向传播
yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy	
前向传播:
	1.由输入数据和权重参数相乘后得到得分值
	2.由得分值计算的到一个loss值
反向传播:
	loss值一步一步往回传,得到权重w更新的力度

加法门单元:均等分配（x+y=q）
MAX门单元: 梯度分给比较大的值(3x+2y=q)
乘法门单元: 互换的感觉(xy=q)







	
